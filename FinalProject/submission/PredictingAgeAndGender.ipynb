{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries, create document class to hold info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  /Data/celebs-usa/female contains 381 texts by females\n",
    "#  /Data/celebs-usa/male contains 912 texts by males\n",
    "#  /Data/celebs-other-json contains text by\n",
    "\n",
    "# Identify birth year as that is a constant, these tweets are from 2011-2018, age range constantly changes but birth year stays constant\n",
    "# using birth year, predict age 10-15, 15-20, 20-25, 25-30, 30-35, 35-40, 45-55,55+  \n",
    "#{'25-34', '35-44', '45-54', '55-64', '65+'}\n",
    "\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, splitext, split\n",
    "import json\n",
    "from collections import Counter\n",
    "import ftfy\n",
    "import re\n",
    "import nltk\n",
    "import copy\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ndjson\n",
    "import pickle\n",
    "import os\n",
    "import jsonlines\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "        \n",
    "hashtag_re = re.compile(r\"#\\w+\")\n",
    "mention_re = re.compile(r\"@\\w+\")\n",
    "url_re = re.compile(r\"(?:https?://)?(?:[-\\w]+\\.)+[a-zA-Z]{2,9}[-\\w/#~:;.?+=&%@~]*\")\n",
    "\n",
    "def preprocess(text):\n",
    "    p_text = hashtag_re.sub(\"[hashtag]\",text)\n",
    "    p_text = mention_re.sub(\"[mention]\",p_text)\n",
    "    p_text = url_re.sub(\"[url]\",p_text)\n",
    "    p_text = ftfy.fix_text(p_text)\n",
    "    return p_text.lower()\n",
    "\n",
    "tokenise_re = re.compile(r\"(\\[[^\\]]+\\]|[-'\\w]+|[^\\s\\w\\[']+)\") #([]|words|other non-space)\n",
    "def tokenise(text):\n",
    "    return tokenise_re.findall(text)\n",
    "\n",
    "        \n",
    "class Document:\n",
    "    def __init__(self, meta={}):\n",
    "        self.meta = meta\n",
    "        self.tokens_fql = Counter() #empty Counter, ready to be added to with Counter.update.\n",
    "        self.pos_fql = Counter()\n",
    "        self.pos_list = [] #empty list for pos tags from running text.\n",
    "        self.num_tokens = 0\n",
    "        \n",
    "    def extract_features_from_text(self, text):\n",
    "        p_text = preprocess(text)\n",
    "        tokens = tokenise(p_text)\n",
    "        self.num_tokens += len(tokens)\n",
    "        self.tokens_fql.update(tokens) #updating Counter counts items in list, adding to existing Counter items.\n",
    "        pos_tagged = nltk.pos_tag(tokens)\n",
    "        pos = [tag[1] for tag in pos_tagged]\n",
    "        self.pos_fql.update(pos)\n",
    "        self.pos_list.extend(pos)\n",
    "        \n",
    "    def extract_features_from_texts(self, texts): #texts should be iterable text lines, e.g. read in from file.\n",
    "        for text in texts:\n",
    "            extract_features_from_text(text)\n",
    "            \n",
    "    def average_token_length(self):\n",
    "        sum_lengths = 0\n",
    "        for key, value in self.tokens_fql.items():\n",
    "            sum_lengths += len(key) * value\n",
    "        return sum_lengths / self.num_tokens\n",
    "    \n",
    "class DocumentProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, process_method):\n",
    "        self.process_method = process_method\n",
    "    \n",
    "    def fit(self, X, y=None): #no fitting necessary, although could use this to build a vocabulary for all documents, and then limit to set (e.g. top 1000).\n",
    "        return self\n",
    "\n",
    "    def transform(self, documents):\n",
    "        for document in documents:\n",
    "            yield self.process_method(document)\n",
    "            \n",
    "def get_tokens_fql(document):\n",
    "    return document.tokens_fql\n",
    "\n",
    "def get_pos_fql(document):\n",
    "    return document.pos_fql\n",
    "\n",
    "def get_text_stats(document):\n",
    "    ttr = len(document.tokens_fql) / document.num_tokens\n",
    "    return {'avg_token_length': document.average_token_length(), 'ttr': ttr }\n",
    "\n",
    "\n",
    "def read_list(file):\n",
    "    with open(file) as f:\n",
    "        items = []\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            items.append(line.strip())\n",
    "    return items\n",
    "\n",
    "fws = read_list(\"functionwords.txt\")\n",
    "\n",
    "def get_fws_fql(document):\n",
    "    fws_fql = Counter({t: document.tokens_fql[t] for t in fws}) \n",
    "    #dict comprehension, t: fql[t] is token: freq.\n",
    "    return +fws_fql\n",
    "\n",
    "def custom_tokenise(text):\n",
    "    return tokenise_re.findall(text.lower())\n",
    "\n",
    "def preprocess(text):\n",
    "    p_text = hashtag_re.sub(\"[hashtag]\",text)\n",
    "    p_text = mention_re.sub(\"[mention]\",p_text)\n",
    "    p_text = url_re.sub(\"[url]\",p_text)\n",
    "    p_text = ftfy.fix_text(p_text)\n",
    "    return p_text\n",
    "\n",
    "def confusion_matrix_heatmap(cm, index):\n",
    "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
    "    dims = (5, 5)\n",
    "    fig, ax = plt.subplots(figsize=dims)\n",
    "    sns.heatmap(cmdf, annot=True, cmap=\"coolwarm\", center=0)\n",
    "    ax.set_ylabel('Actual')    \n",
    "    ax.set_xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Celebrity Data, converting to Document Class and saving to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This gets the celebrity data and adds the correct gender and ages \n",
    "to each json object with text\n",
    "'''\n",
    "def getCelebData():\n",
    "    path = '/home/jay/Downloads/pan19-celebrity-profiling-training-dataset-2019-01-31/feeds.ndjson'\n",
    "    path2 = '/home/jay/Downloads/pan19-celebrity-profiling-training-dataset-2019-01-31/labels.ndjson'\n",
    "    x=0\n",
    "    # Read in the twitter text\n",
    "    data = []\n",
    "    with jsonlines.open(path) as reader:\n",
    "        for obj in reader:\n",
    "            x+=1\n",
    "            print('Reading no ',x)\n",
    "            data.append(obj)\n",
    "            if len(data) >19999:\n",
    "                break;\n",
    "    # Here the correct labels are identified and paried           \n",
    "    labels = []\n",
    "    with jsonlines.open(path2) as reader:\n",
    "        for obj in reader:\n",
    "            if obj['gender']!='nonbinary':\n",
    "                for d in data:\n",
    "                    if d['id'] == obj['id']:\n",
    "                        d['gender'] = obj['gender']\n",
    "                        d['birthyear'] = obj['birthyear']\n",
    "    return data\n",
    "\n",
    "'''\n",
    "This function returns the 5 year group a year of birth resides in, e.g. 1995 is between 1995-1999 (inclusive 5 year period)\n",
    "'''\n",
    "def getYearRange(yearOfBirth):\n",
    "    YearGroupGap = 5\n",
    "    for minYear in range(1900,2015,YearGroupGap):\n",
    "        maxYear = minYear+YearGroupGap\n",
    "        #print('min: ',minYear,'max: ',maxYear)\n",
    "        if (yearOfBirth >= minYear) and (yearOfBirth < maxYear):\n",
    "            return( str(minYear)+'-'+str(maxYear-1) )\n",
    "    raise Exception('year of Birth passed in - ' + str(yearOfBirth)+' is not in range of min and max years' ) \n",
    "    \n",
    "\n",
    "'''\n",
    "This helper function uses the Document class to return a doc\n",
    "class for each user with the correct gender, age and tweets\n",
    "'''\n",
    "def getDocument(data):\n",
    "    try:\n",
    "        gender    = data['gender']\n",
    "        birthyear = data['birthyear']\n",
    "        if data['birthyear'] != 'unknown':\n",
    "            birthYearRange = getYearRange(data['birthyear'])\n",
    "\n",
    "        doc = Document({'gender': gender, 'birthyear':birthyear, 'birthyearrange':birthYearRange}) #include metadata\n",
    "        for tweet in data['text']:\n",
    "            doc.extract_features_from_text(tweet)\n",
    "        return doc\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "\n",
    "'''\n",
    "Check if the pickle file exists, if not then create it, else read in\n",
    "'''\n",
    "corpus = []\n",
    "if os.path.exists(\"/home/jay/Documents/AppliedDataMining/FinalProject/Data/CelebFile\"):\n",
    "    with open('/home/jay/Documents/AppliedDataMining/FinalProject/Data/CelebFile', 'rb') as fp:\n",
    "        corpus = pickle.load(fp)\n",
    "    corpus = []\n",
    "    for i in range(5000):\n",
    "        path = '/home/jay/Documents/AppliedDataMining/FinalProject/Data/20000Celebs/'\n",
    "        path += 'Celeb'+str(i)\n",
    "        with open(path, 'rb') as fp:\n",
    "            obj = pickle.load(fp)\n",
    "            if obj is not None:\n",
    "                corpus.append(obj)\n",
    "            print('done ',i)\n",
    "\n",
    "        \n",
    "    print('CELEB FILE EXISTS')\n",
    "else:\n",
    "    print('CELEB FILE DOES NOT EXISTS, CREATING')\n",
    "    # Call the function to get the twitter data\n",
    "    corpus = getCelebData()\n",
    "    print('Read unprocessed, saving to file')\n",
    "    #with open('/home/jay/Documents/AppliedDataMining/FinalProject/Data/UnProcessedCelebFile', 'wb') as fpc:\n",
    "    #    pickle.dump(corpus, fpc)\n",
    "    print('Saved to file')\n",
    "    #For each json object, convert it to a document object\n",
    "    for i in range(len(corpus)):\n",
    "        print('Doing Obj Number: ',i)\n",
    "        corpus[i] = getDocument(corpus[i])\n",
    "    \n",
    "    with open('/home/jay/Documents/AppliedDataMining/FinalProject/Data/CelebFile', 'wb') as fp:\n",
    "        pickle.dump(corpus, fp)\n",
    "    print('CELEB FILE CREATED')\n",
    "print('OUT ERE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [d for d in corpus if d.meta['gender'] != 'nonbinary']\n",
    "#Get all the birth years and plot a histogram\n",
    "birth_year_y = [d.meta['birthyear'] for d in corpus]\n",
    "x = pd.Series(birth_year_y, name=\"Birth Year\")\n",
    "sns.distplot(x)\n",
    "\n",
    "#Get a count of of the birth years and plot a bar chart\n",
    "df = pd.DataFrame.from_dict(Counter(birth_year_y), orient='index').reset_index()\n",
    "df.columns = ['Year','Frequency of people born']\n",
    "df = df.sort_values(by=['Year'])\n",
    "df.plot.bar(x='Year', y='Frequency of people born', rot=90,figsize=(10,10), title='The number of people born in each year')\n",
    "#BirthYearDF = copy.deepcopy(df)\n",
    "\n",
    "\n",
    "#Get all the birth years and plot a histogram\n",
    "birth_year_y = [d.meta['birthyearrange'] for d in corpus]\n",
    "df1 = pd.DataFrame.from_dict(Counter(birth_year_y), orient='index').reset_index()\n",
    "df1.columns = ['Year','Frequency of people born']\n",
    "df1 = df1.sort_values(by=['Year'])\n",
    "df1.plot.bar(x='Year', y='Frequency of people born', rot=90,figsize=(10,10), title='The number of people born in each year')\n",
    "\n",
    "\n",
    "#Get all the genders and plot a bar chart\n",
    "gender_y = [d.meta['gender'] for d in corpus]\n",
    "df2 = pd.DataFrame.from_dict(Counter(gender_y), orient='index').reset_index()\n",
    "df2.columns = ['Gender','Frequency of Gender']\n",
    "df2.plot.bar(x='Gender', y='Frequency of Gender', rot=90,figsize=(10,10), title='The number of people born in each year')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Train and Test Split + Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "'''\n",
    "Undersample men \n",
    "'''\n",
    "femaleCorpus = [d for d in corpus if d.meta['gender'] == 'female']\n",
    "maleCorpus   = [d for d in corpus if d.meta['gender'] == 'male']\n",
    "genderCorpus = maleCorpus[:len(femaleCorpus)] + femaleCorpus\n",
    "\n",
    "#Getting gender Train and Test\n",
    "gender_y = [d.meta['gender'] for d in genderCorpus]\n",
    "gender_X = genderCorpus\n",
    "Gender_X_train, Gender_X_test, Gender_y_train, Gender_y_test = train_test_split(gender_X,gender_y, test_size=0.3, random_state = 0)\n",
    "genderCorpus = [d for d in corpus if d.meta['gender'] != 'nonbinary']\n",
    "\n",
    "'''\n",
    "Calculate the average year and undersample ages so all the ages that are overrepresented (above the average frequency)\n",
    "then they are decreased to the average frequency\n",
    "'''\n",
    "BirthYearDF = df.reset_index(drop=True)\n",
    "averageFrequency = round(BirthYearDF['Frequency of people born'].mean())\n",
    "BirthYearsThatNeedUnderSampling = BirthYearDF.loc[BirthYearDF['Frequency of people born'] > averageFrequency]\n",
    "BirthYearsThatNeedUnderSampling = BirthYearsThatNeedUnderSampling.set_index('Year') #.T.to_dict('list')\n",
    "BirthYearsThatNeedUnderSampling = BirthYearsThatNeedUnderSampling.to_dict()\n",
    "BirthYearsThatNeedUnderSampling = BirthYearsThatNeedUnderSampling.get('Frequency of people born')\n",
    "\n",
    "itemsToDelete = []\n",
    "for c in corpus:\n",
    "    itemBirthYear = c.meta['birthyear']\n",
    "    if itemBirthYear in BirthYearsThatNeedUnderSampling:\n",
    "        FrequencyOfRow = BirthYearsThatNeedUnderSampling[itemBirthYear]\n",
    "        if FrequencyOfRow > averageFrequency:\n",
    "            itemsToDelete.append(c)\n",
    "            BirthYearsThatNeedUnderSampling[itemBirthYear] -= 1\n",
    "            print('Removed one ',itemBirthYear)\n",
    "print('Done')\n",
    "\n",
    "    \n",
    "corpus = [celeb for celeb in corpus if celeb not in itemsToDelete]\n",
    "\n",
    "#Getting Birth_year_range Train and Test\n",
    "birth_year_y = [d.meta['birthyearrange'] for d in corpus]\n",
    "birth_year_y = [d.meta['birthyear'] for d in corpus]\n",
    "birth_year_X = corpus\n",
    "Birth_X_train, Birth_X_test, Birth_y_train, Birth_y_test = train_test_split(birth_year_X,birth_year_y, test_size=0.3, random_state = 0)\n",
    "genderCorpus = [d for d in corpus if d.meta['gender'] != 'nonbinary']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GenderCount = Counter(gender_y)\n",
    "BirthYearCount = Counter(birth_year_y)\n",
    "print(GenderCount)\n",
    "print('---------------')\n",
    "print(BirthYearCount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection, GridSearch to identify best classifier and best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline ,FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier, VotingClassifier, BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score\n",
    "#from sklean.metrics import metrics\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.feature_extraction import FeatureHasher\n",
    "import pickle\n",
    "\n",
    "\n",
    "model = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('word', Pipeline([\n",
    "                ('processor', DocumentProcessor(process_method = get_pos_fql)),\n",
    "                ('vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "        ],\n",
    "    )),\n",
    "    ('clf', None), # to be set by grid search.\n",
    "])\n",
    "\n",
    "param_grid={ 'clf': [LogisticRegression(solver='liblinear', random_state=0)\n",
    "                     ,MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
    "                     RandomForestClassifier(),\n",
    "                    MLPClassifier(max_iter=400)\n",
    "                    ],\n",
    "    \n",
    "            'union__word__processor__process_method': [get_tokens_fql, get_fws_fql, get_pos_fql, get_text_stats],}\n",
    "\n",
    "\n",
    "search = GridSearchCV(model, cv = StratifiedKFold(n_splits=5, random_state=0), \n",
    "                      return_train_score = False, \n",
    "                      scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'],\n",
    "                      refit = 'f1_weighted',\n",
    "                      param_grid = param_grid\n",
    "                     )\n",
    "\n",
    "\n",
    "\n",
    "print('Fitting Clf')\n",
    "search.fit(Gender_X_train, Gender_y_train)\n",
    "print('Getting Predictions')\n",
    "predictions = search.predict(Gender_X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(Gender_y_test, predictions))\n",
    "print(classification_report(Gender_y_test, predictions))\n",
    "print(confusion_matrix(Gender_y_test, predictions))\n",
    "\n",
    "confusion_matrix_heatmap(confusion_matrix(Gender_y_test,predictions), ['M','F'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Birth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "regr = linear_model.LinearRegression()\n",
    "reg = linear_model.BayesianRidge()\n",
    "\n",
    "no_estimators= 10\n",
    "\n",
    "#Ada boost SVR with pos_fql\n",
    "clf = SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
    "AdaBoostSVR = BaggingRegressor(clf, n_estimators=no_estimators, random_state=0)\n",
    "Pipeline_AdaBoostSVR_get_pos_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_fws_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', AdaBoostSVR),\n",
    "])\n",
    "\n",
    "#Ada boost Random Forest with pos_fql\n",
    "clf = RandomForestRegressor(n_estimators=100)\n",
    "AdaBoostRandomForest = BaggingRegressor(clf, n_estimators=no_estimators, random_state=0)\n",
    "Pipeline_AdaBoostRandomForest_get_pos_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_fws_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', AdaBoostRandomForest),\n",
    "])\n",
    "\n",
    "#Ada boost Bayesian Ridge with pos_fql\n",
    "clf = linear_model.BayesianRidge()\n",
    "AdaBoostBayesianRidge = BaggingRegressor(clf, n_estimators=no_estimators, random_state=0)\n",
    "Pipeline_AdaBoostBayesianRidge_get_pos_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_pos_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', AdaBoostRandomForest),\n",
    "])\n",
    "\n",
    "#Ada boost SVR with pos_fql\n",
    "clf = SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
    "AdaBoostSVR = BaggingRegressor(clf, n_estimators=no_estimators, random_state=0)\n",
    "Pipeline_AdaBoostSVR_get_fws_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_pos_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', AdaBoostSVR),\n",
    "])\n",
    "\n",
    "\n",
    "'''\n",
    "Creating Master Pipeline to fit each ensemble and average the result\n",
    "'''\n",
    "PipeLineList = [Pipeline_AdaBoostRandomForest_get_pos_fql, \n",
    "                Pipeline_AdaBoostSVR_get_pos_fql,\n",
    "                Pipeline_AdaBoostSVR_get_fws_fql,\n",
    "                Pipeline_AdaBoostBayesianRidge_get_pos_fql]\n",
    "\n",
    "predictions= [0] * len(Birth_X_test)\n",
    "x = 0\n",
    "print('Fitting clfs')\n",
    "for pipeline in PipeLineList:\n",
    "    x+=1\n",
    "    print('Fitting Clf number ',x)\n",
    "    pipeline.fit(Birth_X_train, Birth_y_train)\n",
    "    print('Getting Predictions ', x)\n",
    "    predictions += pipeline.predict(Birth_X_test)\n",
    "\n",
    "predictions = predictions / len(PipeLineList)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Birth Year Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('RMSE: ', math.sqrt(mean_squared_error(predictions,Birth_y_test)))\n",
    "print('MSLE: ', mean_squared_log_error(predictions,Birth_y_test))\n",
    "print('R2 Score: ', r2_score(predictions,Birth_y_test))\n",
    "print('MAE: ', mean_absolute_error(predictions,Birth_y_test))\n",
    "\n",
    "\n",
    "res = pd.DataFrame( data = {'Predictions': predictions, 'Actual': Birth_y_test} )\n",
    "res[:100].plot( colormap='Paired')\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(Birth_y_test, predictions))\n",
    "print(classification_report(Birth_y_test, predictions))\n",
    "print(confusion_matrix(Birth_y_test, predictions))\n",
    "\n",
    "\n",
    "#labels = list(set(Birth_y_test+predictions))\n",
    "\n",
    "confusion_matrix_heatmap(confusion_matrix(Birth_y_test,predictions)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_estimators= 1\n",
    "\n",
    "#Ada boost SVM with pos_fql\n",
    "SVM = SVC(probability=True, kernel='linear', verbose=True)\n",
    "Pipeline_SVM_get_pos_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_tokens_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', SVM),\n",
    "])\n",
    "\n",
    "#Ada boost Random Forest with pos_fql\n",
    "MLP = MLPClassifier(random_state=0, verbose=1, max_iter=50)\n",
    "Pipeline_MLP_get_pos_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_tokens_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', MLP),\n",
    "])\n",
    "\n",
    "#Ada boost Random Forest with pos_fql\n",
    "Pipeline_MLP_get_FWS_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_fws_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', MLP),\n",
    "])\n",
    "\n",
    "\n",
    "#Ada boost Random Forest with pos_fql\n",
    "LR = LogisticRegression(verbose=1)\n",
    "Pipeline_LR_get_FWS_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_fws_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', LR),\n",
    "])\n",
    "\n",
    "\n",
    "#Ada boost Bayesian Ridge with pos_fql\n",
    "AdaBoostLogisticRegression = LogisticRegression(verbose=1)\n",
    "Pipeline_LR_get_pos_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_tokens_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', AdaBoostLogisticRegression),\n",
    "])\n",
    "\n",
    "#Ada boost SVR with fws_fql\n",
    "RandForest = RandomForestClassifier(n_estimators=100, verbose=1)\n",
    "Pipeline_RandForest_get_fws_fql = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_tokens_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('clf', RandForest),\n",
    "])\n",
    "\n",
    "GenderPipeline = VotingClassifier(\n",
    "    estimators=[('MLP', Pipeline_MLP_get_pos_fql),\n",
    "                ('MLP2', Pipeline_MLP_get_FWS_fql),\n",
    "                ('LR', Pipeline_LR_get_pos_fql),\n",
    "                ('LR1', Pipeline_LR_get_pos_fql), \n",
    "                ('LR2', Pipeline_LR_get_pos_fql),\n",
    "                ('LR3', Pipeline_LR_get_FWS_fql),\n",
    "                ('randfor', Pipeline_RandForest_get_fws_fql)\n",
    "               ],\n",
    "                voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Gender Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy_score(Gender_y_test, predictions))\n",
    "print(classification_report(Gender_y_test, predictions))\n",
    "print(confusion_matrix(Gender_y_test, predictions))\n",
    "\n",
    "confusion_matrix_heatmap(confusion_matrix(Gender_y_test, predictions), ['Male', 'Female'])\n",
    "\n",
    "res = pd.DataFrame( data = {'Predictions': predictions, 'Actual': Gender_y_test} )\n",
    "\n",
    "res = res.replace(['male', 'female'], [1, 0])\n",
    "\n",
    "res[:20].plot( colormap='Paired')\n",
    "\n",
    "math.sqrt(mean_squared_error(predictions,Gender_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Stacked Generalisation Meta Classifier Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# The stacked generalisation meta classifier (SGMC) is a combination of the gender ensemble and the birth year ensemble\n",
    "\n",
    "#First the outputs of the of the predicted birth year from each of the bagging regressors need to be saved\n",
    "\n",
    "#Then the output of predicted gender needs to be saved, along with the true birth year\n",
    "\n",
    "So now a dataset with the following structure is created, where X are the features \n",
    "(outputs of the ensembles) and Y is the true birth year.\n",
    "\n",
    "   X                         Y\n",
    "1995,1994,1997,1999,1       1995\n",
    "...................................\n",
    "..................................\n",
    "..................................\n",
    "..................................\n",
    "............\n",
    "\n",
    "\n",
    "Once this has been done, the MLP Regressor can then be trained \n",
    "using the stacked generalisation method of hold one out\n",
    "\n",
    "StackedGeneralisationData = pd.DataFrame({\"BirthYearPrediction1\":[], \n",
    "                                        \"BirthYearPrediction2\":[],\n",
    "                                        \"BirthYearPrediction3\":[],\n",
    "                                        \"BirthYearPrediction4\":[],\n",
    "                                        \"GenderPrediction\":[]\n",
    "                                        \"TrueValue\":[]\n",
    "                                       }) \n",
    "'''\n",
    "\n",
    "#Retrieving saved models from file\n",
    "GenderEnsemblePath = '/home/jay/Documents/AppliedDataMining/FinalProject/Classifiers/GenderEnsemble'\n",
    "BirthYearEnsemblePath = '/home/jay/Documents/AppliedDataMining/FinalProject/Classifiers/BirthYearEnsemble'\n",
    "PipeLineList      = pickle.load(open(BirthYearEnsemblePath, 'rb'))\n",
    "GenderPipeline    = pickle.load(open(GenderEnsemblePath, 'rb'))\n",
    "\n",
    "#File is created to save SGMC training data\n",
    "StackedGeneralisationTrainingData = '/home/jay/Documents/AppliedDataMining/FinalProject/Data/StackedGeneralisationTrainingData.csv'\n",
    "  \n",
    "x = 0\n",
    "for observation in corpus:\n",
    "        x+=1\n",
    "        #First the outputs of the of the predicted birth year from each of the bagging regressors need to be saved\n",
    "        print('Getting Predictions ', x)\n",
    "        BirthYearPrediction1 = PipeLineList[0].predict([observation])[0]\n",
    "        BirthYearPrediction2 = PipeLineList[1].predict([observation])[0]\n",
    "        BirthYearPrediction3 = PipeLineList[2].predict([observation])[0]\n",
    "        BirthYearPrediction4 = PipeLineList[3].predict([observation])[0]\n",
    "        GenderPrediction = GenderPipeline.predict([observation])[0]\n",
    "        if GenderPrediction == 'male':\n",
    "            GenderPrediction = 1\n",
    "        else:\n",
    "            GenderPrediction = 0\n",
    "        \n",
    "        true_value = observation.meta['birthyear']\n",
    "        \n",
    "        # Creating the first Dataframe using dictionary \n",
    "        StackedGeneralisation_Append = pd.DataFrame({\"BirthYearPrediction1\":[BirthYearPrediction1], \n",
    "                                                \"BirthYearPrediction2\":[BirthYearPrediction2],\n",
    "                                                \"BirthYearPrediction3\":[BirthYearPrediction3],\n",
    "                                                \"BirthYearPrediction4\":[BirthYearPrediction4],\n",
    "                                                \"GenderPrediction\":[GenderPrediction],\n",
    "                                                \"TrueValue\":[true_value]\n",
    "                                               }) \n",
    "        #Saving data to file\n",
    "        with open(StackedGeneralisationTrainingData, 'a') as f:\n",
    "            StackedGeneralisation_Append.to_csv(f, header=False)  \n",
    "        print('done ', x )\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SGMC and Getting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "StackedGeneralisationTrainingDataPath = '/home/jay/Documents/AppliedDataMining/FinalProject/Data/StackedGeneralisationTrainingData.csv'\n",
    "\n",
    "StackedGeneralisationTrainingData = pd.read_csv(StackedGeneralisationTrainingDataPath)\n",
    "StackedGeneralisationTrainingData = StackedGeneralisationTrainingData.reset_index(drop=True)\n",
    "\n",
    "X = StackedGeneralisationTrainingData[['BirthYearPrediction1','BirthYearPrediction2','BirthYearPrediction3','BirthYearPrediction4','GenderPrediction']]\n",
    "y = StackedGeneralisationTrainingData[['TrueValue']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "#SGMC = RandomForestRegressor(n_estimators=300)\n",
    "#SGMC = MLPRegressor()\n",
    "SGMC = linear_model.LinearRegression()\n",
    "print('Training')\n",
    "SGMC.fit(X_train,y_train)\n",
    "print('Predicting')\n",
    "predictions = SGMC.predict(X_test)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Stacked Generalisation Meta Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE: ', math.sqrt(mean_squared_error(predictions,y_test)))\n",
    "print('MSLE: ', mean_squared_log_error(predictions,y_test))\n",
    "print('R2 Score: ', r2_score(predictions,y_test))\n",
    "print('MAE: ', mean_absolute_error(predictions,y_test))\n",
    "res = pd.DataFrame( data = {'Predictions': predictions, 'Actual': y_test['TrueValue']} )\n",
    "res[:100].plot( colormap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The SGMC and Gender Ensemble on Tweets from Family + Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on friends and family\n",
    "import pickle\n",
    "GenderEnsemblePath = '/home/jay/Documents/AppliedDataMining/FinalProject/Classifiers/GenderEnsemble'\n",
    "BirthYearEnsemblePath = '/home/jay/Documents/AppliedDataMining/FinalProject/Classifiers/BirthYearEnsemble'\n",
    "PipeLineList      = pickle.load(open(BirthYearEnsemblePath, 'rb'))\n",
    "GenderPipeline    = pickle.load(open(GenderEnsemblePath, 'rb'))\n",
    "\n",
    "path = 'alishapatel28_tweets.json'\n",
    "#path = 'ashnapatel_tweets.json'\n",
    "#path = 'paytonmmusic_tweets.json'\n",
    "\n",
    "def SGMC_Predict(observation):\n",
    "    BirthYearPrediction1 = PipeLineList[0].predict([observation])[0]\n",
    "    BirthYearPrediction2 = PipeLineList[1].predict([observation])[0]\n",
    "    BirthYearPrediction3 = PipeLineList[2].predict([observation])[0]\n",
    "    BirthYearPrediction4 = PipeLineList[3].predict([observation])[0]\n",
    "    GenderPrediction = GenderPipeline.predict([observation])[0]\n",
    "    if GenderPrediction == 'male':\n",
    "        GenderPrediction = 1\n",
    "    else:\n",
    "        GenderPrediction = 0    \n",
    "        \n",
    "    # Creating the first Dataframe using dictionary \n",
    "    StackedGeneralisation_Append = pd.DataFrame({\"BirthYearPrediction1\":[BirthYearPrediction1], \n",
    "                                                \"BirthYearPrediction2\":[BirthYearPrediction2],\n",
    "                                                \"BirthYearPrediction3\":[BirthYearPrediction3],\n",
    "                                                \"BirthYearPrediction4\":[BirthYearPrediction4],\n",
    "                                                \"GenderPrediction\":[GenderPrediction],\n",
    "                                        \n",
    "                                               }) \n",
    "    return SGMC.predict(StackedGeneralisation_Append)\n",
    "\n",
    "    \n",
    "def getTestData():\n",
    "    # Read in the twitter text\n",
    "    data = []\n",
    "    with open(path) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "\n",
    "    return data\n",
    "\n",
    "def getTestDocument(data):\n",
    "    try:\n",
    "        doc = Document({}) #include metadata\n",
    "        for tweet in data:\n",
    "            doc.extract_features_from_text(tweet['full_text'])\n",
    "        return doc\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "        \n",
    "TestCorpus = getTestData()\n",
    "TestCorpus = getTestDocument(TestCorpus)\n",
    "PredictedBirthYear = 0\n",
    "PredictedGender = ''\n",
    "PredictedBirthYear = SGMC_Predict(TestCorpus)\n",
    "PredictedGender = GenderPipeline.predict([TestCorpus])     \n",
    "print('Predicted Birth-Year for: ', path, 'is: ', PredictedBirthYear)\n",
    "print('Predicted Age for ', path, 'is: ', 2018 - PredictedBirthYear )\n",
    "print('Predicted Gender for: ', path, 'is: ', PredictedGender)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
