{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship attribution (of single Tweets)\n",
    "\n",
    "In previous labs you have classified collections of Tweets (for a single user) as one document/instance in the classifier. Here, we instead treat individual tweets as documents, and attempt to classify these. We use authorship attribution as the task here, i.e. predicting the user who produced the Tweet.\n",
    "\n",
    "Below are imports and helper functions from previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftfy\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, splitext, split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For POS tagger, incase these haven't been previously downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of methods for showing classifier results (from 1st classification lab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_scores_summary(name, scores):\n",
    "    print(\"{}: mean = {:.2f}%, sd = {:.2f}%, min = {:.2f}, max = {:.2f}\".format(name, scores.mean()*100, scores.std()*100, scores.min()*100, scores.max()*100))\n",
    "    \n",
    "def confusion_matrix_heatmap(cm, index):\n",
    "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
    "    dims = (10, 10)\n",
    "    fig, ax = plt.subplots(figsize=dims)\n",
    "    sns.heatmap(cmdf, annot=True, cmap=\"coolwarm\", center=0)\n",
    "    ax.set_ylabel('Actual')    \n",
    "    ax.set_xlabel('Predicted')\n",
    "    \n",
    "def confusion_matrix_percent_heatmap(cm, index):\n",
    "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
    "    percents = cmdf.div(cmdf.sum(axis=1), axis=0)*100\n",
    "    dims = (10, 10)\n",
    "    fig, ax = plt.subplots(figsize=dims)\n",
    "    sns.heatmap(percents, annot=True, cmap=\"coolwarm\", center=0, vmin=0, vmax=100)\n",
    "    ax.set_ylabel('Actual')    \n",
    "    ax.set_xlabel('Predicted')\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, 25, 50, 75, 100])\n",
    "    cbar.set_ticklabels(['0%', '25%', '50%', '75%', '100%'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for processing text, and producing a Document class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_re = re.compile(r\"#\\w+\")\n",
    "mention_re = re.compile(r\"@\\w+\")\n",
    "url_re = re.compile(r\"(?:https?://)?(?:[-\\w]+\\.)+[a-zA-Z]{2,9}[-\\w/#~:;.?+=&%@~]*\")\n",
    "\n",
    "def preprocess(text):\n",
    "    p_text = hashtag_re.sub(\"[hashtag]\",text)\n",
    "    p_text = mention_re.sub(\"[mention]\",p_text)\n",
    "    p_text = url_re.sub(\"[url]\",p_text)\n",
    "    p_text = ftfy.fix_text(p_text)\n",
    "    return p_text.lower()\n",
    "\n",
    "tokenise_re = re.compile(r\"(\\[[^\\]]+\\]|[-'\\w]+|[^\\s\\w\\[']+)\") #([]|words|other non-space)\n",
    "def tokenise(text):\n",
    "    return tokenise_re.findall(text)\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, meta={}):\n",
    "        self.meta = meta\n",
    "        self.tokens_fql = Counter() #empty Counter, ready to be added to with Counter.update.\n",
    "        self.pos_fql = Counter()\n",
    "        self.pos_list = [] #empty list for pos tags from running text.\n",
    "        self.num_tokens = 0\n",
    "        self.text = \"\"\n",
    "        \n",
    "    def extract_features_from_text(self, text):\n",
    "        self.text += text\n",
    "        p_text = preprocess(text)\n",
    "        tokens = tokenise(p_text)\n",
    "        self.num_tokens += len(tokens)\n",
    "        self.tokens_fql.update(tokens) #updating Counter counts items in list, adding to existing Counter items.\n",
    "        pos_tagged = nltk.pos_tag(tokens)\n",
    "        pos = [tag[1] for tag in pos_tagged]\n",
    "        self.pos_fql.update(pos)\n",
    "        self.pos_list.extend(pos)\n",
    "        \n",
    "    def extract_features_from_texts(self, texts): #texts should be iterable text lines, e.g. read in from file.\n",
    "        for text in texts:\n",
    "            extract_features_from_text(text)\n",
    "            \n",
    "    def average_token_length(self):\n",
    "        sum_lengths = 0\n",
    "        for key, value in self.tokens_fql.items():\n",
    "            sum_lengths += len(key) * value\n",
    "        return sum_lengths / self.num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Tweets as single Document, with metadata of user included. You could utilise other metadata to predict party of user (or age/gender from celebs data) of a single Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tweets_json(folder):\n",
    "    jsonfiles = [join(folder, f) for f in listdir(folder) if isfile(join(folder, f)) and f.endswith(\".json\")]\n",
    "    for jf in jsonfiles:\n",
    "        with open(jf) as f:\n",
    "            data = json.load(f)\n",
    "            tweets = data.pop('tweets')\n",
    "            metadata = data\n",
    "        print(\"Processing \" + metadata['screen_name'])\n",
    "        for tweet in tweets:\n",
    "            doc = Document(meta=metadata)\n",
    "            doc.extract_features_from_text(tweet['text'])\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "corpus.extend(import_tweets_json(\"mps-json-10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d.meta['screen_name'] for d in corpus]\n",
    "X = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 0, stratify=y)\n",
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformer to convert `Document` to extract features via a callable method, below (as in Week 18 lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, process_method):\n",
    "        self.process_method = process_method\n",
    "    \n",
    "    def fit(self, X, y=None): #no fitting necessary, although could use this to build a vocabulary for all documents, and then limit to set (e.g. top 1000).\n",
    "        return self\n",
    "\n",
    "    def transform(self, documents):\n",
    "        for document in documents:\n",
    "            yield self.process_method(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_fql(document):\n",
    "    return document.tokens_fql\n",
    "\n",
    "def get_pos_fql(document):\n",
    "    return document.pos_fql\n",
    "\n",
    "def get_text_stats(document):\n",
    "    ttr = len(document.tokens_fql) / document.num_tokens\n",
    "    return {'avg_token_length': document.average_token_length(), 'ttr': ttr }\n",
    "\n",
    "def read_list(file):\n",
    "    with open(file) as f:\n",
    "        items = []\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            items.append(line.strip())\n",
    "    return items\n",
    "\n",
    "fws = read_list(\"functionwords.txt\")\n",
    "\n",
    "def get_fws_fql(document):\n",
    "    fws_fql = Counter({t: document.tokens_fql[t] for t in fws}) #dict comprehension, t: fql[t] is token: freq.\n",
    "    return +fws_fql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample pipeline to be used with gridsearch, with a feature union of pos tags, words or function words, and some text stats. Using either a naive bayes or logisitic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('pos', Pipeline([\n",
    "                ('processor', DocumentProcessor(process_method = get_pos_fql)),\n",
    "                ('vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "            ('word', Pipeline([\n",
    "                ('processor', DocumentProcessor(process_method = None)), # to be set by grid search.\n",
    "                ('vectorizer', DictVectorizer()),\n",
    "                ('binarize', Binarizer())\n",
    "            ])),\n",
    "            ('stats', Pipeline([\n",
    "                ('processor', DocumentProcessor(process_method = get_text_stats)),\n",
    "                ('vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "        ],\n",
    "    )),\n",
    "    ('selector', SelectKBest(score_func = chi2)),\n",
    "    ('clf', None), # to be set by grid search.\n",
    "])\n",
    "\n",
    "param_grid={\n",
    "    'union__word__processor__process_method': [get_fws_fql, get_tokens_fql],\n",
    "    'selector__k': [100, 'all'],\n",
    "    'clf': [MultinomialNB(), LogisticRegression(solver='liblinear', random_state=0, multi_class='ovr')],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, cv = StratifiedKFold(n_splits=5, random_state=0), \n",
    "                      return_train_score = False, \n",
    "                      scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'],\n",
    "                      refit = 'f1_weighted',\n",
    "                      param_grid = param_grid\n",
    "                     )\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = search.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "confusion_matrix_percent_heatmap(confusion_matrix(y_test,predictions), search.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once evaluated, we can see that we can predict the author of a Tweet quite accurately, with some users easier to predict than others. Why might this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform some error analysis by looking at the text alongside the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_texts = [x.text for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(X_test_texts,y_test,predictions)), columns=[\"Tweet\", \"Actual\", \"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 300\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can see when Theresa May's tweets are predicted incorrectly: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Actual'].str.match(\"@theresa_may\") & ~df['Predicted'].str.match(\"@theresa_may\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or when predicted as a specific other person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Actual'].str.match(\"@theresa_may\") & df['Predicted'].str.match(\"@jeremycorbyn\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Task\n",
    "\n",
    "The classifier above works quite well, but could be made better by utilising different features, e.g. hashtags, emojis, mentions, any much more besides. Expand the feature set and evaluate the impact. You could also use the celebs data, or use a larger set of authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
